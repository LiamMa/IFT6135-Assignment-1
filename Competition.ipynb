{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Competition.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"W4cJNxCqYbyo","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision\n","from torchvision import transforms\n","\n","torch.backends.cudnn.deterministic=True\n","device = torch.device(\"cuda\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kbqXpObvEY69","colab_type":"code","colab":{}},"cell_type":"code","source":["def generate_csv(test_predictions):\n","    \n","    csv_file  = open(\"/content/gdrive/My Drive/submission.csv\", \"w\")\n","    \n","    csv_file.write(\"id,label\")\n","    \n","    for i in range(len(test_predictions)):\n","        \n","        csv_file.write('\\n')\n","        csv_file.write(str(i+1))\n","        csv_file.write(',')\n","\n","        if test_predictions[i] == 0 :\n","            csv_file.write(\"Cat\")   \n","            \n","        elif test_predictions[i] == 1:\n","            csv_file.write(\"Dog\")\n","            \n","    csv_file.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"63qHSCeqYibW","colab_type":"code","outputId":"1d8246f8-817d-4d36-92f3-1ec6ae4c80c2","executionInfo":{"status":"ok","timestamp":1549918521837,"user_tz":300,"elapsed":27277,"user":{"displayName":"Maximilien Le Clei","photoUrl":"https://lh4.googleusercontent.com/-MWdkEHlJfJ8/AAAAAAAAAAI/AAAAAAAAALk/iuE1yhmpMCI/s64/photo.jpg","userId":"17481473454263177289"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"3iSyrAijvgSi","colab_type":"code","colab":{}},"cell_type":"code","source":["X_test = np.load('/content/gdrive/My Drive/Datasets/CatsDogs/test.npy')\n","y_test = np.zeros(4999)\n","\n","X_cats = np.load('/content/gdrive/My Drive/Datasets/CatsDogs/cats.npy')\n","y_cats = np.zeros(9999)\n","\n","X_dogs = np.load('/content/gdrive/My Drive/Datasets/CatsDogs/dogs.npy')\n","y_dogs = np.ones(9999)\n","\n","X_train = np.concatenate((X_cats, X_dogs))\n","y_train = np.concatenate((y_cats, y_dogs))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U1feNZ1YYjrO","colab_type":"code","colab":{}},"cell_type":"code","source":["class CatDogDataset(Dataset):\n","\n","    def __init__(self, X, y):\n","        \n","        self.X = X\n","        self.y = y\n","        \n","        self.len = (X.shape[0])\n","        \n","    def __getitem__(self, i):\n","        \n","        return torch.from_numpy(np.moveaxis(self.X[i], -1, 0)).type(torch.FloatTensor), int(self.y[i])\n","\n","    def __len__(self):\n","        \n","        return self.len"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iEeyMDMqxVzJ","colab_type":"code","colab":{}},"cell_type":"code","source":["test_dataset = CatDogDataset(X_test, y_test)\n","train_dataset = CatDogDataset(X_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gjm3PJ6J4jvg","colab_type":"code","colab":{}},"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=66, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=4999, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p1l7oDihCRU-","colab_type":"code","colab":{}},"cell_type":"code","source":["class SmallVGG(nn.Module):\n","    \n","    \n","    def __init__(self):\n","        \n","        super().__init__()\n","\n","        m = 2  \n","            \n","        # ~~ SmallVGGNET ~~ #\n","            \n","        # Convolutional block # 1   \n","            \n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=3)\n","                \n","        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n","            \n","            \n","        # Convolutional block # 2 \n","            \n","        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n","            \n","            \n","        # Convolutional block # 3\n","            \n","        self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv6 = nn.Conv2d(64, 64, 3, padding=1)\n","            \n","            \n","        # Fully connected block\n","            \n","        self.fc1 = nn.Linear(64*8*8, m)\n","        \n","        \n","    def forward(self, x):\n","        \n","        out = F.relu( self.conv1(x) )\n","        out = F.relu( self.conv2(out) )\n","        out = F.max_pool2d(out, 2)\n","            \n","        out = F.relu( self.conv3(out) )\n","        out = F.relu( self.conv4(out) )\n","        out = F.max_pool2d(out, 2)\n","\n","        out = F.relu( self.conv5(out) )\n","        out = F.relu( self.conv6(out) )\n","        out = F.max_pool2d(out, 2)\n","\n","        out = out.view(out.size(0), -1)\n","\n","        out = self.fc1(out)\n","        \n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"stuWnT4xC48-","colab_type":"code","colab":{}},"cell_type":"code","source":["class Model:\n","    \n","    def __init__(self, architecture):\n","        \n","        self.net = architecture\n","    \n","    def train(self, train_loader, nb_epochs=30):\n","        \n","        #self.net.train()\n","        \n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = optim.SGD(self.net.parameters(), lr=0.005)\n","        \n","        train_accuracy = []\n","        train_er = []\n","        \n","        # Record train values\n","        train_accuracy_epoch, train_er_epoch = self.test(train_loader)\n","        \n","        print(train_er_epoch)\n","        print(train_accuracy_epoch)\n","            \n","        train_accuracy.append(train_accuracy_epoch)\n","        train_er.append(train_er_epoch)\n","        \n","        # Start training\n","        \n","        for epoch in range(nb_epochs):\n","            \n","            print('\\nEpoch', epoch+1)\n","     \n","            for i, (X_batch, y_batch) in enumerate(train_loader):\n","        \n","                # Send the batch to the GPU\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","                # Reset the gradients to zero\n","                optimizer.zero_grad()\n","        \n","                # Forward propagation\n","                y_hat_batch = self.net(X_batch)\n","        \n","                # Compute loss\n","                loss = criterion(y_hat_batch, y_batch)\n","            \n","                # Backward propagation\n","                loss.backward()\n","            \n","                # Update weights\n","                optimizer.step()\n","                \n","            # Record train values\n","            train_accuracy_epoch, train_er_epoch = self.test(train_loader)\n","            \n","            print(train_er_epoch)\n","            print(train_accuracy_epoch)\n","            \n","            train_accuracy.append(train_accuracy_epoch)\n","            train_er.append(train_er_epoch)\n","                                                       \n","        return train_accuracy, train_er\n","            \n","        \n","    def test(self, data_loader):\n","        \n","        #self.net.eval()\n","        \n","        criterion = nn.CrossEntropyLoss()\n","        \n","        with torch.no_grad():\n","        \n","            accuracy = 0\n","            correct_predictions = 0\n","            empirical_risk = 0\n","            \n","            for X_batch, y_batch in data_loader:\n","            \n","                # Send the batch to the GPU\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","            \n","                # Forward propagation\n","                y_hat_batch = self.net(X_batch)\n","                \n","                # Compute loss\n","                loss = criterion(y_hat_batch, y_batch)\n","            \n","                # Pick up most predicted class\n","                _, predictions = torch.max(y_hat_batch.data, 1)\n","                \n","                # Compare predictions and real label\n","                correct_predictions += (predictions == y_batch).sum().item()\n","                \n","                # Sum losses\n","                empirical_risk += loss  \n","        \n","        accuracy = (correct_predictions / len(data_loader.dataset)) * 100\n","        empirical_risk /= len(data_loader)\n","        \n","        return accuracy, empirical_risk\n","    \n","    \n","    def predict(self, data_loader):\n","        \n","        #self.net.eval()\n","        \n","        predictions = np.zeros( len(data_loader.dataset) )\n","        \n","        with torch.no_grad():\n","        \n","            for i, (X_batch, y_batch) in enumerate(data_loader):\n","            \n","                # Send the batch to the GPU\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","            \n","                y_hat_batch = self.net(X_batch)\n","            \n","                _, batch_predicictions = torch.max(y_hat_batch.data, 1)\n","                predictions[i * X_batch.shape[0] : (i+1) * X_batch.shape[0]] = batch_predicictions.cpu().numpy()\n","                \n","        return predictions"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jlAIcWCsDJJN","colab_type":"code","outputId":"203d6b1e-b108-41e9-d016-f3f66e5852c7","executionInfo":{"status":"error","timestamp":1549900068944,"user_tz":300,"elapsed":10508,"user":{"displayName":"Maximilien Le Clei","photoUrl":"https://lh4.googleusercontent.com/-MWdkEHlJfJ8/AAAAAAAAAAI/AAAAAAAAALk/iuE1yhmpMCI/s64/photo.jpg","userId":"17481473454263177289"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","\n","cnn = SmallVGG().to(device)\n","\n","model  = Model(cnn)\n","\n","train_accuracy, train_er = model.train(train_loader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor(0.7172, device='cuda:0')\n","48.099809980998096\n","\n","Epoch 1\n","tensor(0.6564, device='cuda:0')\n","61.431143114311425\n","\n","Epoch 2\n","tensor(0.6325, device='cuda:0')\n","64.46644664466447\n","\n","Epoch 3\n"],"name":"stdout"}]},{"metadata":{"id":"fIho8ELdBkOX","colab_type":"code","colab":{}},"cell_type":"code","source":["test_predictions = model.predict(test_loader)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UoB31iIbC5Cm","colab_type":"code","colab":{}},"cell_type":"code","source":["test_predictions.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fQ8jFLK_Cfz-","colab_type":"code","colab":{}},"cell_type":"code","source":["generate_csv(test_predictions)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tWE7EgDnCl9m","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}