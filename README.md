# IFT6135-Assignment
> Jin Dong: jin.dong@mail.mcgill.ca;
> Liheng Ma: liheng.ma@mail.mcgill.ca

This is the assignment codebase for the IFT-6135: Learning Representation (Deep Learning) class taught by Prof Aaron C at the UdeM.

## Assignment 1: CNN

1. Implement MLP with vectorized back-propogation using Numpy.
2. Implement a standard CNN for MNIST.
3. Implement an improved CNN for MNIST on Kaggle using DL library (we used MxNet).

## Assignment 2: RNN

1. Implement a RNN, GRU Cell using PyTorch.
2. Implement the multi-head self-attention module of Transformer.
3. Do experiments on various setting.

## Assignment 3: Generative model

1. Build a discriminator to approximate Wasserstein Distance, Jensenâ€“Shannon divergence, etc.
2. Build a Variational Auto-encoder with binary-cross-entropy loss to generate binarized MNIST images.
3. Build a Variational Auto-encoder with MSE loss to generate SVHN images.
4. Build a Wasserstein GAN with gradient-penalty to generate SVHN images.
5. Qualitative and quantative analyze the performance of VAE and GAN.
