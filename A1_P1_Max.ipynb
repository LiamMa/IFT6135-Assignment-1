{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"A1_P1_Max.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"NBVBGiqBGaGV","colab_type":"text"},"cell_type":"markdown","source":["# Setup"]},{"metadata":{"id":"1ZmGTwN2Fdvn","colab_type":"code","colab":{}},"cell_type":"code","source":["# For Google Collab\n","\n","# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aezmD0iyFhbl","colab_type":"code","outputId":"4db0a184-2e1b-472f-fb81-2805cff93de7","executionInfo":{"status":"ok","timestamp":1548109833499,"user_tz":300,"elapsed":2171,"user":{"displayName":"Maximilien Le Clei","photoUrl":"https://lh4.googleusercontent.com/-MWdkEHlJfJ8/AAAAAAAAAAI/AAAAAAAAALk/iuE1yhmpMCI/s64/photo.jpg","userId":"17481473454263177289"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"f8v_2HS_FWok","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eJGlLnz6FWon","colab_type":"code","colab":{}},"cell_type":"code","source":["def one_hot(old_y, m):\n","    \n","    n = len(old_y)\n","    \n","    y = np.zeros((n, m))\n","    \n","    y[np.arange(n), old_y] = 1\n","    \n","    return y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fyyXtznUFl31","colab_type":"code","colab":{}},"cell_type":"code","source":["# ~~ MNIST dataset ~~\n","\n","X_train = np.load('/content/gdrive/My Drive/Datasets/MNIST/x_train.npy')\n","y_train = one_hot(np.load('/content/gdrive/My Drive/Datasets/MNIST/y_train.npy'), 10)\n","\n","X_val = np.load('/content/gdrive/My Drive/Datasets/MNIST/x_val.npy')\n","y_val = one_hot(np.load('/content/gdrive/My Drive/Datasets/MNIST/y_val.npy'), 10)\n","\n","X_test = np.load('/content/gdrive/My Drive/Datasets/MNIST/x_test.npy')\n","y_test = one_hot(np.load('/content/gdrive/My Drive/Datasets/MNIST/y_test.npy'), 10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L7f4RiOeFWoo","colab_type":"text"},"cell_type":"markdown","source":["# Model"]},{"metadata":{"id":"d0DOsVFLFWoy","colab_type":"code","colab":{}},"cell_type":"code","source":["class NN:\n","    \n","    # ----- Initializations ----- #\n","    \n","    def initialize_weights(self, n_hidden, dims, initialization_scheme):\n","    \n","        # Zero    \n","        if initialization_scheme == 'Zero':\n","            \n","            for i in range(n_hidden + 1):\n","            \n","                # Weights set to 0\n","            \n","                self.W.append( np.zeros(( dims[i+1], dims[i] )) )\n","        \n","                # Biases set to 0\n","            \n","                self.b.append( np.zeros( dims[i+1] ) )\n","        \n","        # Normal        \n","        elif initialization_scheme == 'Normal':\n","            \n","            for i in range(n_hidden + 1):\n","            \n","                # Weights sampled from N(0,1)\n","            \n","                self.W.append( np.random.randn( dims[i+1], dims[i] ) )\n","        \n","                # Biases set to 0\n","            \n","                self.b.append( np.zeros( dims[i+1] ) )\n","        \n","        # Glorot        \n","        else: #initialization_scheme == 'Glorot'\n","            \n","            for i in range(n_hidden + 1):            \n","            \n","                # Weights sampled from U(-d^l, d^l), d^l = sqrt( 6 / h^(l-1) + h^l )\n","            \n","                d = np.sqrt( 6 / dims[i] + dims[i+1] )\n","            \n","                self.W.append( np.random.uniform( -d, d, (dims[i+1], dims[i]) ) )\n","        \n","                # Biases ~ 0\n","            \n","                self.b.append( np.zeros(dimensions[i+1]) )\n","    \n","    \n","    # ----- ReLU activation ----- #\n","    \n","    def activation(self, inputs):\n","        \n","        zeros = np.zeros_like(inputs)\n","        \n","        return np.maximum(zeros, inputs)\n","    \n","    \n","    # ----- Softmax ----- #\n","    \n","    def softmax(self, inputs):\n","        \n","        # Numerically stable softmax\n","        \n","        b = np.max(inputs, axis=1)\n","        \n","        return np.exp(inputs - b) / np.sum( np.exp(inputs - b), axis=1 )\n","    \n","        \n","    # ----- Update weights ----- #\n","    \n","    def update(self, grads, eta):\n","        \n","        grad_W, grad_b = grads\n","        \n","        for l in range(self.n_hidden + 1):\n","                    \n","            self.W[l] -= eta * grad_W[l]\n","            self.b[l] -= eta * grad_b[l]\n","        \n","    # ----- Constructor ----- #\n","        \n","    def __init__(self, hidden_dims, n_hidden, initialization_scheme):\n","        \n","        dims = [784] + hidden_dims + [10]\n","        \n","        self.W = []\n","        self.b = []\n","        \n","        self.n_hidden = n_hidden\n","        \n","        self.initialize_weights(n_hidden, dims, initialization_scheme)\n","    \n","    # ----- Train ----- #\n","    \n","    def train(self, X, y, epochs, eta):\n","            \n","        n = len(X)\n","            \n","        # Stochastic Gradient Descent\n","            \n","        for epoch in range(epochs):\n","                \n","            empirical_risk = 0\n","            accuracy = 0\n","                \n","            for i in range(n):\n","                \n","                # Forward pass\n","                [y_hat], loss, _ = self.forward(X[i].reshape((1,784)), y[i])                 \n","                \n","                empirical_risk += loss / n\n","                \n","                accuracy += int(np.argmax(y[i]) == y_hat)\n","                \n","                # Backward pass\n","                    \n","                grads = self.backward(X[i], y[i])\n","                \n","                self.update(grads, eta)\n","                \n","                if i % 500 == 0:\n","                    print(i / 500, '%')\n","            \n","            print('Epoch', i+1)\n","            print('Empirical risk', empirical_risk)\n","            print('Accuracy', accuracy, '%')\n","                       \n","    # ----- Cross Entropy Loss ----- #\n","    \n","    def loss(self, prediction, label):\n","        \n","        L_x = - np.log(prediction + 0.00001) # To avoid log(0)\n","        \n","        return np.sum(L_x * label, axis=1)\n","        \n","        \n","    # ----- Forward Propagation ----- #\n","    \n","    def forward(self, X, y):\n","    \n","        n = len(X)\n","    \n","        self.a = [X]\n","    \n","        self.h = []\n","    \n","        for i in range(self.n_hidden):\n","            \n","            self.h.append( np.matmul(self.a[i], self.W[i].T) + self.b[i] )\n","            \n","            self.a.append( self.activation(self.h[i])  )\n","            \n","        self.h_output = np.matmul(self.a[-1], self.W[-1].T) + self.b[-1]\n","        \n","        self.a_output = self.softmax(self.h_output)\n","        \n","        y_hat = np.argmax(self.a_output, axis=1)\n","        \n","        accuracy = np.sum(y == y_hat) / n\n","        \n","        return y_hat, self.loss(self.a_output, y), accuracy\n","    \n","    \n","    # ----- Backward Propagation ----- #\n","    \n","    def backward(self, X, y):\n","        \n","        # Set up list storing gradients\n","\n","        grad_W = []\n","        grad_b = []\n","\n","        for i in range(self.n_hidden + 1):\n","            \n","            grad_W.append(None)\n","            grad_b.append(None)\n","            \n","        for i in range(self.n_hidden, -1, -1):\n","            \n","            # Softmax\n","            if i == self.n_hidden:\n","                grad_h = self.a_output\n","                grad_h -= y\n","            \n","            # ReLU\n","            else: \n","                grad_h = grad_a * ( (self.h[i] > 0) * 1 )\n","            \n","            grad_W[i] = np.matmul(grad_h.T, self.a[i])\n","            \n","            grad_b[i] = np.sum(grad_h, axis=0)\n","            \n","            grad_a = np.matmul(grad_h, self.W[i])\n","        \n","        return (grad_W, grad_b)"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":false,"id":"oM0s8ZnXFWo0","colab_type":"code","outputId":"877bd59d-e140-40f7-a38d-6a9098cd1277","colab":{"base_uri":"https://localhost:8080/","height":2262},"executionInfo":{"status":"error","timestamp":1548116074194,"user_tz":300,"elapsed":361719,"user":{"displayName":"Maximilien Le Clei","photoUrl":"https://lh4.googleusercontent.com/-MWdkEHlJfJ8/AAAAAAAAAAI/AAAAAAAAALk/iuE1yhmpMCI/s64/photo.jpg","userId":"17481473454263177289"}}},"cell_type":"code","source":["model = NN(hidden_dims=[666, 666], n_hidden=2, initialization_scheme='Normal')\n","\n","model.train(X_train, y_train, 10, 0.05)\n","\n"],"execution_count":79,"outputs":[{"output_type":"stream","text":["0.0 %\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n","  return umr_maximum(a, axis, None, out, keepdims)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:187: RuntimeWarning: invalid value encountered in greater\n"],"name":"stderr"},{"output_type":"stream","text":["1.0 %\n","2.0 %\n","3.0 %\n","4.0 %\n","5.0 %\n","6.0 %\n","7.0 %\n","8.0 %\n","9.0 %\n","10.0 %\n","11.0 %\n","12.0 %\n","13.0 %\n","14.0 %\n","15.0 %\n","16.0 %\n","17.0 %\n","18.0 %\n","19.0 %\n","20.0 %\n","21.0 %\n","22.0 %\n","23.0 %\n","24.0 %\n","25.0 %\n","26.0 %\n","27.0 %\n","28.0 %\n","29.0 %\n","30.0 %\n","31.0 %\n","32.0 %\n","33.0 %\n","34.0 %\n","35.0 %\n","36.0 %\n","37.0 %\n","38.0 %\n","39.0 %\n","40.0 %\n","41.0 %\n","42.0 %\n","43.0 %\n","44.0 %\n","45.0 %\n","46.0 %\n","47.0 %\n","48.0 %\n","49.0 %\n","50.0 %\n","51.0 %\n","52.0 %\n","53.0 %\n","54.0 %\n","55.0 %\n","56.0 %\n","57.0 %\n","58.0 %\n","59.0 %\n","60.0 %\n","61.0 %\n","62.0 %\n","63.0 %\n","64.0 %\n","65.0 %\n","66.0 %\n","67.0 %\n","68.0 %\n","69.0 %\n","70.0 %\n","71.0 %\n","72.0 %\n","73.0 %\n","74.0 %\n","75.0 %\n","76.0 %\n","77.0 %\n","78.0 %\n","79.0 %\n","80.0 %\n","81.0 %\n","82.0 %\n","83.0 %\n","84.0 %\n","85.0 %\n","86.0 %\n","87.0 %\n","88.0 %\n","89.0 %\n","90.0 %\n","91.0 %\n","92.0 %\n","93.0 %\n","94.0 %\n","95.0 %\n","96.0 %\n","97.0 %\n","98.0 %\n","99.0 %\n","Epoch 50000\n","Empirical risk [nan]\n","Accuracy 4922 %\n","0.0 %\n","1.0 %\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-4360816d7bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m666\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m666\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialization_scheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-5565dfbb860d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs, eta)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-5565dfbb860d>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mgrad_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_a\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mgrad_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mgrad_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}