{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of A1_1_Jin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdongjin/IFT6135-Assignment/blob/master/A1_1_Jin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ajrMnZLJeMHv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgyWZVSD64lB",
        "colab_type": "code",
        "outputId": "6d2feb7d-9ce8-4da2-a866-1539cb0a5efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HN603fuc-9PX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "3c911640-40c0-4cc2-98b3-30ba02da5979"
      },
      "cell_type": "code",
      "source": [
        "def one_hot(labels, n):\n",
        "    \"\"\"labels: m*1 vector\n",
        "       n: expected classes\n",
        "       outout: m*n matrix\"\"\"\n",
        "    m = len(labels)\n",
        "    onehot = np.zeros((m, n))\n",
        "    onehot[np.arange(m), labels] = 1\n",
        "    return onehot\n",
        "\n",
        "DATA_PATH = r'/content/gdrive/My Drive/app/MNIST'\n",
        "X_train = np.load(DATA_PATH + '/x_train.npy')\n",
        "y_train = one_hot(np.load(DATA_PATH + '/y_train.npy'),10)\n",
        "X_val   = np.load(DATA_PATH + '/x_val.npy')\n",
        "y_val   = one_hot(np.load(DATA_PATH + '/y_val.npy'),10)\n",
        "X_test  = np.load(DATA_PATH + '/x_test.npy')\n",
        "y_test  = one_hot(np.load(DATA_PATH + '/y_test.npy'),10)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-3f10e81b86fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/content/gdrive/My Drive/app/MNIST'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/x_train.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/y_train.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_val\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/x_val.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/app/MNIST/x_train.npy'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BXmeo9zw7Swx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y):\n",
        "    return np.sum(1 * np.argmax(y_pred, axis=1) == np.argmax(y, axis=1)) * 100.0 / y.shape[0]\n",
        "\n",
        "\n",
        "def data_iter(data, batch_size):\n",
        "    X, y = data\n",
        "    batches = [(X[i:i+batch_size],y[i:i+batch_size]) for i in range(0,X.shape[0],batch_size)]\n",
        "    random.shuffle(batches)\n",
        "    for batch in batches:\n",
        "        yield batch\n",
        "                \n",
        "        \n",
        "def glorot(in_dim, out_dim):\n",
        "    d = np.sqrt(6/(in_dim+out_dim))\n",
        "    return np.random.uniform(-d,d,(in_dim,out_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UONENIM-fV0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = 784\n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "class NN(object):\n",
        "    \n",
        "    \n",
        "    def __init__(self,hidden_dims=[1024,2048],n_hidden=2,init='Normal',activate='relu'):\n",
        "        self.dims = [INPUT_DIM,] + hidden_dims + [OUTPUT_DIM,]\n",
        "        self.weights = []\n",
        "        self.biases  = []\n",
        "        self.init = init\n",
        "        self.activate = activate\n",
        "        \n",
        "        self.initialize_weights(n_hidden, self.dims)\n",
        "        \n",
        "        \n",
        "    def initialize_weights(self, n_hidden, dims):\n",
        "        init_method = None\n",
        "        if self.init == 'Zero':\n",
        "            init_method = lambda x, y: np.zeros((x,y))\n",
        "        elif self.init == 'Normal':\n",
        "            init_method = lambda x, y: np.random.randn(x,y)\n",
        "        elif self.init == 'Glorot':\n",
        "            init_method = glorot\n",
        "        else:\n",
        "            raise Exception('Choose right initialization method.')\n",
        "            \n",
        "        for (inputs, outputs) in zip(dims[:-1], dims[1:]):\n",
        "            self.weights.append(init_method(inputs, outputs))\n",
        "            self.biases.append(np.zeros(outputs))\n",
        "            \n",
        "            \n",
        "    def activation(self,inputs):\n",
        "        if self.activate == 'relu':\n",
        "            inputs[inputs < 0] = 0\n",
        "            return inputs\n",
        "        if self.activate == 'sigmoid':\n",
        "            return 1.0/(1.0+np.exp(-inputs))\n",
        "\n",
        "        \n",
        "    def loss(self, pred, labels):\n",
        "        '''\n",
        "        Negative log likelihood\n",
        "        '''\n",
        "        ls = np.nan_to_num(np.log(pred))\n",
        "        ls = - np.sum(labels * ls)\n",
        "        return ls / pred.shape[0]\n",
        "            \n",
        "        \n",
        "    def forward(self, inputs, labels):\n",
        "        a_k = None\n",
        "        h_k = inputs\n",
        "        a = []\n",
        "        h = [h_k]\n",
        "        for (W, b) in zip(self.weights[:-1], self.biases[:-1]):\n",
        "            a_k = np.dot(h_k, W) + b\n",
        "            h_k = self.activation(a_k)\n",
        "            a.append(a_k)\n",
        "            h.append(h_k)\n",
        "        \n",
        "        a_k = np.dot(h_k, self.weights[-1]) + self.biases[-1]\n",
        "        h_k = self.softmax(a_k)\n",
        "        a.append(a_k)\n",
        "        h.append(h_k)\n",
        "        \n",
        "        ls = self.loss(h_k, labels)\n",
        "        cache = (a, h)\n",
        "        \n",
        "        return h_k, ls, cache\n",
        "    \n",
        "    \n",
        "    def backward(self,cache,labels,lss):\n",
        "        \"\"\"\n",
        "        Input: cache: (as, hs)\n",
        "                    as: preactivate values\n",
        "                    hs: activated values\n",
        "                    lss: loss\n",
        "        output: grads: (grads_w, grads_b)\n",
        "        \"\"\"\n",
        "        as_ = cache[0]\n",
        "        hs_ = cache[1]\n",
        "        \n",
        "        nabla_w = [np.zeros_like(w) for w in self.weights]\n",
        "        nabla_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "        # nabla l -> softmax -> pre-softmax\n",
        "        nabla_a = -(labels - hs_[-1])\n",
        "        nabla_b[-1] = np.sum(nabla_a, axis=0)\n",
        "        nabla_w[-1] = np.dot(hs_[-2].T, nabla_a)\n",
        "        # for each preactivate -> activation layer\n",
        "        for layer in range(2, len(self.dims)):\n",
        "            nabla_h = np.dot(nabla_a, self.weights[-layer+1].T)\n",
        "            nabla_a = nabla_h * self.activate_grad(as_[-layer])\n",
        "\n",
        "            nabla_b[-layer] = np.sum(nabla_a, axis=0)\n",
        "            nabla_w[-layer] = np.dot(hs_[-layer-1].T, nabla_a)\n",
        "\n",
        "        nabla_w = [x / labels.shape[0] for x in nabla_w]\n",
        "        nabla_b = [x / labels.shape[0] for x in nabla_b]\n",
        "        return (nabla_w,nabla_b)\n",
        "   \n",
        "        \n",
        "    def update(self,grads,lr):\n",
        "        grads_w, grads_b = grads\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] -= lr * grads_w[i]\n",
        "            self.biases[i] -= lr * grads_b[i]\n",
        "            \n",
        "\n",
        "    def train(self, data, epochs, batch_size, lr, lambd=0.0, test_data=None):\n",
        "        l_acc = []\n",
        "        l_ls  = []\n",
        "        for ep in range(1, epochs+1):\n",
        "            print('Epoch',ep,':')\n",
        "            for (batch_x, batch_y) in data_iter(data, batch_size):\n",
        "                y_pred, ls, cache = self.forward(batch_x, batch_y)\n",
        "                grads = self.backward(cache, batch_y, ls)\n",
        "                self.update(grads, lr)\n",
        "            if test_data:\n",
        "                acc, ls = self.test(test_data)\n",
        "                l_acc.append(acc)\n",
        "                l_ls.append(ls)\n",
        "                print('Epoch %i (acc, loss):(%s,%s)' % (ep, acc, ls))\n",
        "        return l_acc, l_ls\n",
        "\n",
        "                \n",
        "    def test(self, data):\n",
        "        x, y = data\n",
        "        outputs, ls, _ = self.forward(x, y)\n",
        "        return accuracy(outputs, y), ls\n",
        "        \n",
        "    \n",
        "    def activate_grad(self,inputs):\n",
        "        if self.activate == 'relu':\n",
        "            inputs[inputs > 0] = 1\n",
        "            inputs[inputs < 0] = 0\n",
        "            return inputs\n",
        "        elif self.activate == 'sigmiod':\n",
        "            return self.activation(inputs) * (1 - self.activation(inputs))\n",
        "        \n",
        "        \n",
        "    def softmax(self,inputs):\n",
        "        inputs = inputs - np.max(inputs, axis=1).reshape(inputs.shape[0],1)\n",
        "        outputs = np.exp(inputs)\n",
        "        return outputs / (np.sum(outputs, axis=1).reshape(inputs.shape[0],1))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhIq8JQMCIK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialization\n",
        "\n",
        "number of hidden units per layer:\n",
        "total number of parameters:\n",
        "nonlinearity activation:\n",
        "learning rate:\n",
        "mini-batch size:"
      ]
    },
    {
      "metadata": {
        "id": "3rZ6REJwva-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2506
        },
        "outputId": "9f5ad3ff-c473-49cc-f342-d9db5eeff0f7"
      },
      "cell_type": "code",
      "source": [
        "nn1 = NN(hidden_dims=[900,600],n_hidden=2,init='Zero')\n",
        "zero_acc, zero_ls = nn1.train((X_train,y_train), epochs=10, batch_size=200, lr=0.01, test_data=(X_train,y_train))\n",
        "nn2 = NN(hidden_dims=[900,600],n_hidden=2,init='Normal')\n",
        "normal_acc, normal_ls = nn2.train((X_train,y_train), epochs=10, batch_size=200, lr=0.01, test_data=(X_train,y_train))\n",
        "nn3 = NN(hidden_dims=[900,600],n_hidden=2,init='Glorot')\n",
        "glorot_acc, glorot_ls = nn3.train((X_train,y_train), epochs=10, batch_size=200, lr=0.01, test_data=(X_train,y_train))\n",
        "\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 15, 10\n",
        "\n",
        "plt.xticks(np.arange(0, 11, step=1))\n",
        "plt.xlabel('Epoch', weight='bold')\n",
        "plt.ylabel('Average Loss on Training Set', weight='bold')\n",
        "plt.title('Empirical Risk - Training Set - MNIST - 3 Different Initialization Methods', weight='bold')\n",
        "\n",
        "plt.plot(np.arange(1, 11, step=1), normal_acc, label='Normal')\n",
        "plt.plot(np.arange(1, 11, step=1), glorot_acc, label='Glorot')\n",
        "plt.plot(np.arange(1, 11, step=1), zero_acc, label='Zero')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 :\n",
            "Epoch 1 (acc, loss):(11.356,2.301961069176031)\n",
            "Epoch 2 :\n",
            "Epoch 2 (acc, loss):(11.356,2.301582395951002)\n",
            "Epoch 3 :\n",
            "Epoch 3 (acc, loss):(11.356,2.301355417424963)\n",
            "Epoch 4 :\n",
            "Epoch 4 (acc, loss):(11.356,2.3012182355760977)\n",
            "Epoch 5 :\n",
            "Epoch 5 (acc, loss):(11.356,2.3011347759450222)\n",
            "Epoch 6 :\n",
            "Epoch 6 (acc, loss):(11.356,2.301085424407625)\n",
            "Epoch 7 :\n",
            "Epoch 7 (acc, loss):(11.356,2.3010559319781496)\n",
            "Epoch 8 :\n",
            "Epoch 8 (acc, loss):(11.356,2.3010386676388674)\n",
            "Epoch 9 :\n",
            "Epoch 9 (acc, loss):(11.356,2.3010277734997646)\n",
            "Epoch 10 :\n",
            "Epoch 10 (acc, loss):(11.356,2.301021417323032)\n",
            "Epoch 1 :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 (acc, loss):(91.21,inf)\n",
            "Epoch 2 :\n",
            "Epoch 2 (acc, loss):(93.836,inf)\n",
            "Epoch 3 :\n",
            "Epoch 3 (acc, loss):(95.07,inf)\n",
            "Epoch 4 :\n",
            "Epoch 4 (acc, loss):(95.67,inf)\n",
            "Epoch 5 :\n",
            "Epoch 5 (acc, loss):(96.702,inf)\n",
            "Epoch 6 :\n",
            "Epoch 6 (acc, loss):(97.366,inf)\n",
            "Epoch 7 :\n",
            "Epoch 7 (acc, loss):(98.032,inf)\n",
            "Epoch 8 :\n",
            "Epoch 8 (acc, loss):(98.156,inf)\n",
            "Epoch 9 :\n",
            "Epoch 9 (acc, loss):(98.55,inf)\n",
            "Epoch 10 :\n",
            "Epoch 10 (acc, loss):(98.784,3.5953862697246315e+303)\n",
            "Epoch 1 :\n",
            "Epoch 1 (acc, loss):(83.876,0.7916546061448241)\n",
            "Epoch 2 :\n",
            "Epoch 2 (acc, loss):(87.626,0.5037904637246717)\n",
            "Epoch 3 :\n",
            "Epoch 3 (acc, loss):(89.142,0.41305929256269913)\n",
            "Epoch 4 :\n",
            "Epoch 4 (acc, loss):(90.174,0.366835801773168)\n",
            "Epoch 5 :\n",
            "Epoch 5 (acc, loss):(90.712,0.3379712801492887)\n",
            "Epoch 6 :\n",
            "Epoch 6 (acc, loss):(91.24,0.31695695968705934)\n",
            "Epoch 7 :\n",
            "Epoch 7 (acc, loss):(91.652,0.30067185838911853)\n",
            "Epoch 8 :\n",
            "Epoch 8 (acc, loss):(91.994,0.28745810885123585)\n",
            "Epoch 9 :\n",
            "Epoch 9 (acc, loss):(92.318,0.27622436942075296)\n",
            "Epoch 10 :\n",
            "Epoch 10 (acc, loss):(92.586,0.26743175432016525)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-826c0380e4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average loss on training set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[0;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text xticklabel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bbox can be None, so use another sentinel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_property\u001b[0;34m(self, k, v)\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown property %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Unknown property step"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAJDCAYAAABzFEc7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAkhNuAAAAyQk3AACA5P4HoYpB5I1lffgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EaVVXFoPFiNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "53J5SNzMLKgY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parameter Search\n",
        "Architecture : 784 -> 666 -> 666 -> 10 (973,702 parameters)\n",
        "Nonlinearity : ReLU\n",
        "Learning rate : 0.1\n",
        "Mini-batch size : 100\n",
        "Numpy random seed : 0\n",
        "Initialization : Glorot"
      ]
    },
    {
      "metadata": {
        "id": "PKrVkSloLJn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "3fe39461-08f4-49f5-8481-30dc5428facd"
      },
      "cell_type": "code",
      "source": [
        "nn4 = NN(hidden_dims=[666,666],n_hidden=2,init='Glorot')\n",
        "best_acc, best_ls = nn4.train((X_train,y_train), epochs=10, batch_size=100, lr=0.1, test_data=(X_val,y_val))\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 :\n",
            "Epoch 1 (acc, loss):(94.05,0.20935447554445294)\n",
            "Epoch 2 :\n",
            "Epoch 2 (acc, loss):(95.99,0.1478667828157328)\n",
            "Epoch 3 :\n",
            "Epoch 3 (acc, loss):(96.61,0.12020052887266927)\n",
            "Epoch 4 :\n",
            "Epoch 4 (acc, loss):(97.07,0.10148065573105852)\n",
            "Epoch 5 :\n",
            "Epoch 5 (acc, loss):(97.19,0.09322777999335484)\n",
            "Epoch 6 :\n",
            "Epoch 6 (acc, loss):(97.36,0.08999020176704418)\n",
            "Epoch 7 :\n",
            "Epoch 7 (acc, loss):(97.53,0.08053558622466704)\n",
            "Epoch 8 :\n",
            "Epoch 8 (acc, loss):(97.67,0.08124906043340971)\n",
            "Epoch 9 :\n",
            "Epoch 9 (acc, loss):(97.81,0.07730418018852951)\n",
            "Epoch 10 :\n",
            "Epoch 10 (acc, loss):(97.77,0.07211707192557472)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RP6odFvhLqa5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNdnr8gON0gq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validate Gradients using Finite Diﬀerence"
      ]
    },
    {
      "metadata": {
        "id": "dLq72RpSNz7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2036
        },
        "outputId": "5d711340-ca6b-4b50-de69-9d7bf63f95e4"
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "nn5 = NN(hidden_dims=[666,666],n_hidden=2,init='Glorot')\n",
        "i_value = [0,1,3,5]\n",
        "k_value = [1,5]\n",
        "N_value = [k*10**i for i in i_value for k in k_value]\n",
        "p = 10\n",
        "\n",
        "data_number = np.random.randint(0,X_train.shape[0])\n",
        "X, y = X_train[data_number,:].reshape(1,-1), y_train[data_number,:].reshape(1,-1)\n",
        "y_hat, ls, cache = nn5.forward(X,y)\n",
        "print(ls)\n",
        "grad_W, grad_b = nn5.backward(cache, y, ls)\n",
        "\n",
        "grad_theta = grad_W[0][0,:p]\n",
        "\n",
        "res = []\n",
        "\n",
        "for N in N_value:\n",
        "    epsilon = 1 / N\n",
        "    grad_diff = np.zeros(p)\n",
        "    for i in range(p):\n",
        "        \n",
        "        nn5.weights[0][0,i] += epsilon\n",
        "        _, L_plus, _ = nn5.forward(X,y)\n",
        "        \n",
        "        nn5.weights[0][0,i] -= 2*epsilon\n",
        "        _, L_minus,_ = nn5.forward(X,y)\n",
        "        \n",
        "        nn5.weights[0][0,i] += epsilon\n",
        "        \n",
        "        grad_diff[i] = (L_plus/epsilon-L_minus/epsilon) / 2\n",
        "    res.append(np.max(np.abs(grad_theta - grad_diff)))\n",
        "    \n",
        "plt.xlabel('N', weight='bold')\n",
        "plt.ylabel('Target', weight='bold')\n",
        "plt.title('maximum diﬀerence between the true gradient and the ﬁnite diﬀerence gradient', weight='bold')\n",
        "plt.plot(np.arange(len(res)), res)    "
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6392597639551267\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd856b8fdd8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAJbCAYAAABaeJExAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgEAAADAQhiBAAAAAGAhjEAAAAAAsJDfs03h/Apdha0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TrYc_FR5Pex8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "?plt.plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WG28ARMtTDVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}