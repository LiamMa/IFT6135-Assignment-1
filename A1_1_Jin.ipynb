{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of A1_1_Jin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdongjin/IFT6135-Assignment/blob/master/A1_1_Jin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ajrMnZLJeMHv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgyWZVSD64lB",
        "colab_type": "code",
        "outputId": "d1f3f743-13dd-470f-8d82-a47b9eaa2cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HN603fuc-9PX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(labels, n):\n",
        "    \"\"\"labels: m*1 vector\n",
        "       n: expected classes\n",
        "       outout: m*n matrix\"\"\"\n",
        "    m = len(labels)\n",
        "    onehot = np.zeros((m, n))\n",
        "    onehot[np.arange(m), labels] = 1\n",
        "    return onehot\n",
        "\n",
        "DATA_PATH = r'/content/gdrive/My Drive/Datasets/MNIST'\n",
        "X_train = np.load(DATA_PATH + '/x_train.npy')\n",
        "y_train = one_hot(np.load(DATA_PATH + '/y_train.npy'),10)\n",
        "X_val   = np.load(DATA_PATH + '/x_val.npy')\n",
        "y_val   = one_hot(np.load(DATA_PATH + '/y_val.npy'),10)\n",
        "X_test  = np.load(DATA_PATH + '/x_test.npy')\n",
        "y_test  = one_hot(np.load(DATA_PATH + '/y_test.npy'),10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXmeo9zw7Swx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y):\n",
        "    return np.sum(1 * np.argmax(y_pred, axis=1) == np.argmax(y, axis=1)) * 100.0 / y.shape[0]\n",
        "\n",
        "\n",
        "def data_iter(data, batch_size):\n",
        "    X, y = data\n",
        "    batches = [(X[i:i+batch_size],y[i:i+batch_size]) for i in range(0,X.shape[0],batch_size)]\n",
        "    random.shuffle(batches)\n",
        "    for batch in batches:\n",
        "        yield batch\n",
        "                \n",
        "        \n",
        "def glorot(in_dim, out_dim):\n",
        "    d = np.sqrt(6/(in_dim+out_dim))\n",
        "    return np.random.uniform(-d,d,(in_dim,out_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UONENIM-fV0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = 784\n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "class NN(object):\n",
        "    \n",
        "    \n",
        "    def __init__(self,hidden_dims=[1024,2048],n_hidden=2,init='Normal',activate='relu'):\n",
        "        self.dims = [INPUT_DIM,] + hidden_dims + [OUTPUT_DIM,]\n",
        "        self.weights = []\n",
        "        self.biases  = []\n",
        "        self.init = init\n",
        "        self.activate = activate\n",
        "        \n",
        "        self.initialize_weights(n_hidden, self.dims)\n",
        "        \n",
        "        \n",
        "    def initialize_weights(self, n_hidden, dims):\n",
        "        init_method = None\n",
        "        if self.init == 'Zero':\n",
        "            init_method = lambda x, y: np.zeros((x,y))\n",
        "        elif self.init == 'Normal':\n",
        "            init_method = lambda x, y: np.random.randn(x,y)\n",
        "        elif self.init == 'Glorot':\n",
        "            init_method = glorot\n",
        "        else:\n",
        "            raise Exception('Choose right initialization method.')\n",
        "            \n",
        "        for (inputs, outputs) in zip(dims[:-1], dims[1:]):\n",
        "            self.weights.append(init_method(inputs, outputs))\n",
        "            self.biases.append(np.zeros(outputs))\n",
        "            \n",
        "            \n",
        "    def activation(self,inputs):\n",
        "        if self.activate == 'relu':\n",
        "            inputs[inputs < 0] = 0\n",
        "            return inputs\n",
        "        if self.activate == 'sigmoid':\n",
        "            return 1.0/(1.0+np.exp(-inputs))\n",
        "\n",
        "        \n",
        "    def loss(self, pred, labels):\n",
        "        '''\n",
        "        Negative log likelihood\n",
        "        '''\n",
        "        ls = np.nan_to_num(np.log(pred))\n",
        "        ls = - np.sum(labels * ls)\n",
        "        return ls / pred.shape[0]\n",
        "            \n",
        "        \n",
        "    def forward(self, inputs, labels):\n",
        "        a_k = None\n",
        "        h_k = inputs\n",
        "        a = []\n",
        "        h = [h_k]\n",
        "        for (W, b) in zip(self.weights[:-1], self.biases[:-1]):\n",
        "            a_k = np.dot(h_k, W) + b\n",
        "            h_k = self.activation(a_k)\n",
        "            a.append(a_k)\n",
        "            h.append(h_k)\n",
        "        \n",
        "        a_k = np.dot(h_k, self.weights[-1]) + self.biases[-1]\n",
        "        h_k = self.softmax(a_k)\n",
        "        a.append(a_k)\n",
        "        h.append(h_k)\n",
        "        \n",
        "        ls = self.loss(h_k, labels)\n",
        "        cache = (a, h)\n",
        "        \n",
        "        return h_k, ls, cache\n",
        "    \n",
        "    \n",
        "    def backward(self,cache,labels,lss):\n",
        "        \"\"\"\n",
        "        Input: cache: (as, hs)\n",
        "                    as: preactivate values\n",
        "                    hs: activated values\n",
        "                    lss: loss\n",
        "        output: grads: (grads_w, grads_b)\n",
        "        \"\"\"\n",
        "        as_ = cache[0]\n",
        "        hs_ = cache[1]\n",
        "        \n",
        "        nabla_w = [np.zeros_like(w) for w in self.weights]\n",
        "        nabla_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "        # nabla l -> softmax -> pre-softmax\n",
        "        nabla_a = -(labels - hs_[-1])\n",
        "        nabla_b[-1] = np.sum(nabla_a, axis=0)\n",
        "        nabla_w[-1] = np.dot(hs_[-2].T, nabla_a)\n",
        "        # for each preactivate -> activation layer\n",
        "        for layer in range(2, len(self.dims)):\n",
        "            nabla_h = np.dot(nabla_a, self.weights[-layer+1].T)\n",
        "            nabla_a = nabla_h * self.activate_grad(as_[-layer])\n",
        "\n",
        "            nabla_b[-layer] = np.sum(nabla_a, axis=0)\n",
        "            nabla_w[-layer] = np.dot(hs_[-layer-1].T, nabla_a)\n",
        "\n",
        "        nabla_w = [x / labels.shape[0] for x in nabla_w]\n",
        "        nabla_b = [x / labels.shape[0] for x in nabla_b]\n",
        "        return (nabla_w,nabla_b)\n",
        "   \n",
        "        \n",
        "    def update(self,grads,lr):\n",
        "        grads_w, grads_b = grads\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] -= lr * grads_w[i]\n",
        "            self.biases[i] -= lr * grads_b[i]\n",
        "            \n",
        "\n",
        "    def train(self, data, epochs, batch_size, lr, lambd=0.0, test_data=None):\n",
        "        l_acc = []\n",
        "        l_ls  = []\n",
        "        for ep in range(1, epochs+1):\n",
        "            print('Epoch',ep,':')\n",
        "            for (batch_x, batch_y) in data_iter(data, batch_size):\n",
        "                y_pred, ls, cache = self.forward(batch_x, batch_y)\n",
        "                grads = self.backward(cache, batch_y, ls)\n",
        "                self.update(grads, lr)\n",
        "            if test_data:\n",
        "                acc, ls = self.test(test_data)\n",
        "                l_acc.append(acc)\n",
        "                l_ls.append(ls)\n",
        "                print('Epoch %i (acc, loss):(%s,%s)' % (ep, acc, ls))\n",
        "        return l_acc, l_ls\n",
        "\n",
        "                \n",
        "    def test(self, data):\n",
        "        x, y = data\n",
        "        outputs, ls, _ = self.forward(x, y)\n",
        "        return accuracy(outputs, y), ls\n",
        "        \n",
        "    \n",
        "    def activate_grad(self,inputs):\n",
        "        if self.activate == 'relu':\n",
        "            inputs[inputs > 0] = 1\n",
        "            inputs[inputs < 0] = 0\n",
        "            return inputs\n",
        "        elif self.activate == 'sigmiod':\n",
        "            return self.activation(inputs) * (1 - self.activation(inputs))\n",
        "        \n",
        "        \n",
        "    def softmax(self,inputs):\n",
        "        inputs = inputs - np.max(inputs, axis=1).reshape(inputs.shape[0],1)\n",
        "        outputs = np.exp(inputs)\n",
        "        return outputs / (np.sum(outputs, axis=1).reshape(inputs.shape[0],1))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhIq8JQMCIK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialization\n",
        "\n",
        "number of hidden units per layer:\n",
        "total number of parameters:\n",
        "nonlinearity activation:\n",
        "learning rate:\n",
        "mini-batch size:"
      ]
    },
    {
      "metadata": {
        "id": "3rZ6REJwva-1",
        "colab_type": "code",
        "outputId": "8d283a5f-33dc-4d24-fc66-b4e33156c4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "cell_type": "code",
      "source": [
        "nn1 = NN(hidden_dims=[900,600],n_hidden=2,init='Zero')\n",
        "zero_acc, zero_ls = nn1.train((X_train,y_train), epochs=10, batch_size=200, lr=0.01, test_data=(X_train,y_train))\n",
        "nn2 = NN(hidden_dims=[900,600],n_hidden=2,init='Normal')\n",
        "normal_acc, normal_ls = nn2.train((X_train,y_train), epochs=10, batch_size=200, lr=0.01, test_data=(X_train,y_train))\n",
        "nn3 = NN(hidden_dims=[900,600],n_hidden=2,init='Glorot')\n",
        "glorot_acc, glorot_ls = nn3.train((X_train,y_train), epochs=10, batch_size=200, lr=0.01, test_data=(X_train,y_train))\n",
        "\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 15, 10\n",
        "\n",
        "plt.xticks(np.arange(0, 11, step=1))\n",
        "plt.xlabel('Epoch', weight='bold')\n",
        "plt.ylabel('Average Loss on Training Set', weight='bold')\n",
        "plt.title('Empirical Risk - Training Set - MNIST - 3 Different Initialization Methods', weight='bold')\n",
        "\n",
        "plt.plot(np.arange(1, 11, step=1), normal_acc, label='Normal')\n",
        "plt.plot(np.arange(1, 11, step=1), glorot_acc, label='Glorot')\n",
        "plt.plot(np.arange(1, 11, step=1), zero_acc, label='Zero')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7dd7fd3faa8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Zero'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mzero_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnormal_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Glorot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-62122fa19b76>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, epochs, batch_size, lr, lambd, test_data)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-62122fa19b76>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0ma_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mh_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "EaVVXFoPFiNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "53J5SNzMLKgY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parameter Search\n",
        "Architecture : 784 -> 666 -> 666 -> 10\n",
        "\n",
        "parameters:  785\\*666+667\\*666+667\\*10 = 973,702 parameters.\n",
        "\n",
        "Nonlinearity : ReLU\n",
        "\n",
        "Learning rate : 0.1\n",
        "\n",
        "Mini-batch size : 100\n",
        "\n",
        "Numpy random seed : 0\n",
        "\n",
        "Initialization : Glorot"
      ]
    },
    {
      "metadata": {
        "id": "PKrVkSloLJn3",
        "colab_type": "code",
        "outputId": "f999d07b-25d1-4122-8cad-688e32c71658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "nn4 = NN(hidden_dims=[666,666],n_hidden=2,init='Glorot')\n",
        "best_acc, best_ls = nn4.train((X_train,y_train), epochs=10, batch_size=100, lr=0.1, test_data=(X_val,y_val))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8b5f606925ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m666\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m666\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Glorot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-62122fa19b76>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, epochs, batch_size, lr, lambd, test_data)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-62122fa19b76>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0ma_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mh_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RP6odFvhLqa5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNdnr8gON0gq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validate Gradients using Finite Diﬀerence"
      ]
    },
    {
      "metadata": {
        "id": "dLq72RpSNz7r",
        "colab_type": "code",
        "outputId": "688fbab9-dace-45ba-ac72-56e65f4a9699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "nn5 = NN(hidden_dims=[666,666],n_hidden=2,init='Glorot')\n",
        "i_value = [0,1,3,5]\n",
        "k_value = [1,5]\n",
        "N_value = [k*10**i for i in i_value for k in k_value]\n",
        "p = 10\n",
        "\n",
        "\n",
        "data_number = np.random.randint(0,X_train.shape[0])\n",
        "X, y = X_train[data_number,:].reshape(1,-1), y_train[data_number,:].reshape(1,-1)\n",
        "X[:p,0] = 100\n",
        "y_hat, ls, cache = nn5.forward(X,y)\n",
        "print(ls)\n",
        "grad_W, grad_b = nn5.backward(cache, y, ls)\n",
        "\n",
        "grad_theta = grad_W[0][0,:p]\n",
        "\n",
        "res = []\n",
        "\n",
        "for N in N_value:\n",
        "    epsilon = 1 / N\n",
        "    grad_diff = np.zeros(p)\n",
        "    for i in range(p):\n",
        "        \n",
        "        nn5.weights[0][0,i] += epsilon\n",
        "        _, L_plus, _ = nn5.forward(X,y)\n",
        "        \n",
        "        nn5.weights[0][0,i] -= 2*epsilon\n",
        "        _, L_minus,_ = nn5.forward(X,y)\n",
        "        \n",
        "        nn5.weights[0][0,i] += epsilon\n",
        "        \n",
        "        grad_diff[i] = (L_plus/epsilon-L_minus/epsilon) / 2\n",
        "    res.append(np.max(np.abs(grad_theta - grad_diff)))\n",
        "    \n",
        "plt.xlabel('N', weight='bold')\n",
        "plt.ylabel('Target', weight='bold')\n",
        "plt.title('maximum difference between the true gradient and the ﬁnite difference gradient', weight='bold')\n",
        "plt.plot(np.arange(len(res)), res)    "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.512868233288935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa0f6b6ec50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAFnCAYAAABgqKpGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IMKaUBuao4-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# "
      ]
    },
    {
      "metadata": {
        "id": "TrYc_FR5Pex8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WG28ARMtTDVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}