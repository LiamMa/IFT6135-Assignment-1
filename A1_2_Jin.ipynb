{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_2_Jin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdongjin/IFT6135-Assignment/blob/master/A1_2_Jin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-xf9VXLHtte0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pltt\n",
        "import os\n",
        "\n",
        "torch.manual_seed(10)\n",
        "torch.cuda.manual_seed(10)\n",
        "np.random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VYiDH0WSwCud",
        "colab_type": "code",
        "outputId": "36b833d7-67fb-4e78-95c7-878b27cc2b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pcDfEMPE5oEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 200\n",
        "lr = 1e-2\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGXNjj0AuZb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(labels, n):\n",
        "    \"\"\"labels: m*1 vector\n",
        "       n: expected classes\n",
        "       outout: m*n matrix\"\"\"\n",
        "    m = len(labels)\n",
        "    onehot = np.zeros((m, n))\n",
        "    onehot[np.arange(m), labels] = 1\n",
        "    return onehot\n",
        "\n",
        "DATA_PATH = r'/content/gdrive/My Drive/Datasets/MNIST'\n",
        "X_train = torch.from_numpy(np.load(DATA_PATH + '/x_train.npy')).reshape(-1,1,28,28)\n",
        "y_train = torch.from_numpy(np.load(DATA_PATH + '/y_train.npy')).type(torch.LongTensor)\n",
        "X_val   = torch.from_numpy(np.load(DATA_PATH + '/x_val.npy')).reshape(-1,1,28,28)\n",
        "y_val   = torch.from_numpy(np.load(DATA_PATH + '/y_val.npy')).type(torch.LongTensor)\n",
        "X_test  = torch.from_numpy(np.load(DATA_PATH + '/x_test.npy')).reshape(-1,1,28,28)\n",
        "y_test  = torch.from_numpy(np.load(DATA_PATH + '/y_test.npy')).type(torch.LongTensor)\n",
        "\n",
        "train_set = TensorDataset(X_train, y_train)\n",
        "val_set   = TensorDataset(X_val, y_val)\n",
        "test_set  = TensorDataset(X_test, y_test)\n",
        "\n",
        "dev = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mh88msSSw8Kp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet,self).__init__()\n",
        "        \n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 48, kernel_size=(11,11), stride=1) # 18\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=2, padding=1) # 10\n",
        "        self.conv2 = nn.Conv2d(48, 96, kernel_size=(1,1)) # 10\n",
        "        self.conv3 = nn.Conv2d(96,256, kernel_size=(2,2)) # 5\n",
        "        \n",
        "        self.fc    = nn.Linear(256*5*5, 10)\n",
        "        \n",
        "        \n",
        "    def forward(self, X):\n",
        "        output = self.pool1(F.relu(self.conv1(X)))\n",
        "        output = F.relu(self.conv2(output))\n",
        "        output = self.pool1(F.relu(self.conv3(output)))\n",
        "        output = output.view(-1, 256*5*5)\n",
        "        output = self.fc(output)\n",
        "        \n",
        "        return output\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ioZ2o6SyEbLV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train_set, test_set, epochs, batch_size, optimizer):    \n",
        "    global dev\n",
        "    \n",
        "    train_err, train_acc, val_err, val_acc = [], [], [], [] \n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    model.to(dev)\n",
        "    \n",
        "    for ep in range(1, epochs+1):\n",
        "        err = 0.0\n",
        "        acc = 0.0\n",
        "        total = 0\n",
        "        for i, (X,y) in enumerate(train_loader):\n",
        "            X = X.to(dev)\n",
        "            y = y.to(dev)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = model.criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total+= y.size(0)\n",
        "            err += loss\n",
        "            acc += torch.sum(torch.max(y_hat,1)[1] == y)\n",
        "            \n",
        "        train_err.append(err/total)\n",
        "        train_acc.append(acc/total)\n",
        "        \n",
        "        err = 0.0; acc = 0.0; total = 0\n",
        "        for i, (X,y) in enumerate(test_loader):\n",
        "            X = X.to(dev)\n",
        "            y = y.to(dev)\n",
        "            with torch.no_grad():\n",
        "                \n",
        "                y_hat = model(X)\n",
        "                loss  = model.criterion(y_hat, y)\n",
        "                \n",
        "                total += y.size(0)\n",
        "                err += loss\n",
        "                acc += torch.sum(torch.max(y_hat,1)[1] == y)\n",
        "                \n",
        "        val_err.append(err/total)\n",
        "        val_acc.append(acc/total)\n",
        "        \n",
        "    return train_err, train_acc, val_err, val_acc        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V9ESdbvP_nIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = AlexNet()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "train_err, train_acc, val_err, val_acc  = \\\n",
        "    train(model, train_set, test_set, epochs, batch_size, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d4PoiiFcGTMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d1cbcded-a335-40b0-d958-adf643b1b7a8"
      },
      "cell_type": "code",
      "source": [
        "train_acc"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "hFFJHqg3JhxB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}