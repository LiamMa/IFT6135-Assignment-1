{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_3_Jin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "1eGIV7SLuBhP"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdongjin/IFT6135-Assignment/blob/master/A1_3_Jin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1eGIV7SLuBhP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment Setting and Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "W9Scb4r5XYt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "d25eab78-e87b-4fd2-cf51-8905c57ba76f"
      },
      "cell_type": "code",
      "source": [
        "! nvidia-smi\n",
        "! pip install mxnet-cu100"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Feb 10 18:43:22 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    69W / 149W |   6930MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z7yPuUVEwMGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import mxnet as mx\n",
        "from mxnet import autograd, nd, init, gluon\n",
        "from mxnet.gluon import nn, loss as gloss, data as gdata\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vk9K9HmXjiFm",
        "colab_type": "code",
        "outputId": "bc8a7cc6-7932-4399-a518-0cb19c941563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "data_path = '/content/gdrive/My\\ Drive/Datasets/dogcat'\n",
        "base_path = '/content/dogcat'\n",
        "\n",
        "! rm -rf '/content/dogcat'\n",
        "! cp -r $data_path /content\n",
        "\n",
        "for f in ['trainset.zip', 'testset.zip']:\n",
        "    with zipfile.ZipFile(os.path.join(base_path, f)) as z:\n",
        "        z.extractall(base_path)\n",
        "        \n",
        "! rm -rf /content/dogcat/__MACOSX\n",
        "! ls /content/dogcat"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "sample_submission.csv  testset\ttestset.zip  trainset  trainset.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H_4IhW_6w69l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "53bd1d8c-1e21-453f-895d-1f83eb047c52"
      },
      "cell_type": "code",
      "source": [
        "train_valid_path = 'trainset'\n",
        "test_path = 'testset'\n",
        "train_path = 'train'\n",
        "valid_path = 'valid'\n",
        "\n",
        "\n",
        "def delete_dir(path):\n",
        "    if os.path.exists(os.path.join(*path)):\n",
        "        shutil.rmtree(os.path.join(*path))\n",
        "        \n",
        "def create_dir(path):\n",
        "    if not os.path.exists(os.path.join(*path)):\n",
        "        os.makedirs(os.path.join(*path))\n",
        "\n",
        "def devide_train_valid(base_path, train_valid_path, train_path, valid_path,\n",
        "                       valid_ratio=0.2, labels=['Dog', 'Cat']):\n",
        "    delete_dir([base_path, train_path])\n",
        "    delete_dir([base_path, valid_path])\n",
        "        \n",
        "    all_files_by_label = [os.listdir(os.path.join(base_path, train_valid_path, label))\n",
        "                          for label in labels]\n",
        "    \n",
        "    count_train = {label:0 for label in labels}\n",
        "    count_valid = {label:0 for label in labels}\n",
        "    \n",
        "    for label, file_per_label in zip(labels, all_files_by_label):\n",
        "        print('Train&Valid set, %s: %s' % (label, len(file_per_label)))\n",
        "        create_dir([base_path, train_path, label])\n",
        "        create_dir([base_path, valid_path, label])\n",
        "        for f in file_per_label:\n",
        "            if count_train[label] < len(file_per_label) * (1 - valid_ratio):\n",
        "                shutil.copy(os.path.join(base_path, train_valid_path, label, f),\n",
        "                            os.path.join(base_path, train_path, label, f))\n",
        "                count_train[label] += 1\n",
        "            else:\n",
        "                shutil.copy(os.path.join(base_path, train_valid_path, label, f),\n",
        "                            os.path.join(base_path, valid_path, label, f))\n",
        "                count_valid[label] += 1\n",
        "        print('Train set, %s: %s' % (label, count_train[label]))\n",
        "        print('Valid set, %s: %s' % (label, count_valid[label]))\n",
        "                \n",
        "devide_train_valid(base_path, train_valid_path, train_path, valid_path)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train&Valid set, Dog: 9999\n",
            "Train set, Dog: 8000\n",
            "Valid set, Dog: 1999\n",
            "Train&Valid set, Cat: 9999\n",
            "Train set, Cat: 8000\n",
            "Valid set, Cat: 1999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XFhpuWnt4uoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0fcdf823-2841-4f62-d562-ef7f3ee9c7d2"
      },
      "cell_type": "code",
      "source": [
        "os.path.join(base_path, train_path)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dogcat/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "SsDH1T9pwG3B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data_iter(batch_size):\n",
        "    aug_train = gdata.vision.transforms.Compose([\n",
        "    #     gdata.vision.transforms.RandomResizedCrop(64, scale=(0.75, 1),\n",
        "    #                                                ratio=(3.0/4.0, 4.0/3.0)),\n",
        "        gdata.vision.transforms.RandomFlipLeftRight(),\n",
        "        gdata.vision.transforms.RandomColorJitter(brightness=0.4, \n",
        "                                                  contrast=0.4, saturation=0.4),\n",
        "        gdata.vision.transforms.RandomLighting(0.1),\n",
        "        gdata.vision.transforms.ToTensor(),\n",
        "    #     gdata.vision.transforms.Normalize([0.485, 0.456, 0.406], \n",
        "    #                                       [0.229, 0.224, 0.225])\n",
        "\n",
        "    ])\n",
        "\n",
        "    aug_test = gdata.vision.transforms.Compose([\n",
        "        gdata.vision.transforms.ToTensor(),\n",
        "    #     gdata.vision.transforms.Normalize([0.485, 0.456, 0.406], \n",
        "    #                                       [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_data = gdata.vision.ImageFolderDataset(\n",
        "        os.path.join(base_path, train_path), flag=1)\n",
        "    valid_data = gdata.vision.ImageFolderDataset(\n",
        "        os.path.join(base_path, valid_path), flag=1)\n",
        "    train_valid_data = gdata.vision.ImageFolderDataset(\n",
        "        os.path.join(base_path, train_valid_path), flag=1)\n",
        "    test_data = gdata.vision.ImageFolderDataset(\n",
        "        os.path.join(base_path, test_path), flag=1)\n",
        "\n",
        "    train_iter = gdata.DataLoader(train_data.transform_first(aug_train), batch_size,\n",
        "                                  shuffle=True, last_batch='keep')\n",
        "    valid_iter = gdata.DataLoader(valid_data.transform_first(aug_test), batch_size,\n",
        "                                  shuffle=True, last_batch='keep')\n",
        "    train_valid_iter = gdata.DataLoader(train_valid_data.transform_first(aug_train), batch_size,\n",
        "                                  shuffle=True, last_batch='keep')\n",
        "    test_iter  = gdata.DataLoader(test_data.transform_first(aug_test), batch_size,\n",
        "                                  shuffle=False, last_batch='keep')\n",
        "    \n",
        "    return train_iter, valid_iter, train_valid_iter, test_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vk6fUe-Tn0lI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test"
      ]
    },
    {
      "metadata": {
        "id": "3aD2mikE5Hm9",
        "colab_type": "code",
        "outputId": "326c1e0e-bee7-408d-ce22-1048f5f4ff4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1979
        }
      },
      "cell_type": "code",
      "source": [
        "def vgg_block(num_convs, num_channels):\n",
        "    blk = nn.Sequential()\n",
        "    for _ in range(num_convs):\n",
        "        blk.add(nn.Conv2D(num_channels, kernel_size=3,\n",
        "                          padding=1, activation='relu'))\n",
        "    blk.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
        "    return blk\n",
        "\n",
        "\n",
        "def vgg(conv_arch):\n",
        "    net = nn.Sequential()\n",
        "    # 卷积层部分\n",
        "    for (num_convs, num_channels) in conv_arch:\n",
        "        net.add(vgg_block(num_convs, num_channels))\n",
        "    # 全连接层部分\n",
        "    net.add(nn.Dense(512, activation='relu'), nn.Dropout(0.1),\n",
        "            nn.Dense(512, activation='relu'), nn.Dropout(0.1),\n",
        "            nn.Dense(2))\n",
        "    print(net)\n",
        "    return net\n",
        "        \n",
        "lr, num_epochs, batch_size, ctx, wd= 0.05, 20, 128, mx.gpu(), 5e-4\n",
        "lr_period, lr_decay= 80, 0.1\n",
        "\n",
        "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512))\n",
        "vgg11 = vgg(conv_arch)\n",
        "vgg11.initialize(init=init.Xavier(), ctx=ctx)\n",
        "train_iter, valid_iter, train_valid_iter, test_iter = load_data_iter(batch_size)\n",
        "train(vgg11, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period,\n",
        "      lr_decay)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv2D(None -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (4): Dense(None -> 512, Activation(relu))\n",
            "  (5): Dropout(p = 0.1, axes=())\n",
            "  (6): Dense(None -> 512, Activation(relu))\n",
            "  (7): Dropout(p = 0.1, axes=())\n",
            "  (8): Dense(None -> 2, linear)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Ignoring /content/dogcat/trainset/.DS_Store, which is not a directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-73b170de1b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_valid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m train(vgg11, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period,\n\u001b[0;32m---> 64\u001b[0;31m       lr_decay)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-98-73b170de1b31>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period, lr_decay)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlr_period\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36msame_process_iter\u001b[0;34m()\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0msame_process_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_sampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchify_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0msame_process_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_sampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchify_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/data/dataset.py\u001b[0m in \u001b[0;36mbase_fn\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbase_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m_call_cached_op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    813\u001b[0m                     \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish_deferred_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                     \u001b[0mcargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CKpbzNWs4i3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1572
        },
        "outputId": "50ebebb7-ecad-448b-e56c-37d4e83e8408"
      },
      "cell_type": "code",
      "source": [
        "conv_arch = ((1, 32), (1, 64), (2, 128), (2, 256), (2, 256))\n",
        "vgg11 = vgg(conv_arch)\n",
        "vgg11.initialize(init=init.Xavier(), ctx=ctx)\n",
        "train(vgg11, train_valid_iter, valid_iter, 30, batch_size, 5e-2, ctx)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2D(None -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2D(None -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2D(None -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (4): Sequential(\n",
            "    (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
            "  )\n",
            "  (5): Dense(None -> 512, Activation(relu))\n",
            "  (6): Dropout(p = 0.1, axes=())\n",
            "  (7): Dense(None -> 512, Activation(relu))\n",
            "  (8): Dropout(p = 0.1, axes=())\n",
            "  (9): Dense(None -> 2, linear)\n",
            ")\n",
            "epoch 1, train loss 0.6925, train acc 0.5145, time 17.48\n",
            "epoch 1, test acc 0.5000,\n",
            "epoch 2, train loss 0.6906, train acc 0.5419, time 17.07\n",
            "epoch 2, test acc 0.5640,\n",
            "epoch 3, train loss 0.6865, train acc 0.5523, time 17.22\n",
            "epoch 3, test acc 0.5903,\n",
            "epoch 4, train loss 0.6810, train acc 0.5682, time 17.15\n",
            "epoch 4, test acc 0.5895,\n",
            "epoch 5, train loss 0.6746, train acc 0.5781, time 17.15\n",
            "epoch 5, test acc 0.6146,\n",
            "epoch 6, train loss 0.6660, train acc 0.5988, time 17.26\n",
            "epoch 6, test acc 0.5678,\n",
            "epoch 7, train loss 0.6553, train acc 0.6167, time 17.20\n",
            "epoch 7, test acc 0.6301,\n",
            "epoch 8, train loss 0.6420, train acc 0.6305, time 17.18\n",
            "epoch 8, test acc 0.6248,\n",
            "epoch 9, train loss 0.6249, train acc 0.6559, time 17.07\n",
            "epoch 9, test acc 0.6386,\n",
            "epoch 10, train loss 0.6114, train acc 0.6641, time 17.40\n",
            "epoch 10, test acc 0.6963,\n",
            "epoch 11, train loss 0.5952, train acc 0.6825, time 17.27\n",
            "epoch 11, test acc 0.6918,\n",
            "epoch 12, train loss 0.5834, train acc 0.6934, time 17.22\n",
            "epoch 12, test acc 0.7156,\n",
            "epoch 13, train loss 0.5690, train acc 0.7057, time 17.20\n",
            "epoch 13, test acc 0.7346,\n",
            "epoch 14, train loss 0.5542, train acc 0.7145, time 17.26\n",
            "epoch 14, test acc 0.7199,\n",
            "epoch 15, train loss 0.5435, train acc 0.7246, time 17.30\n",
            "epoch 15, test acc 0.7311,\n",
            "epoch 16, train loss 0.5211, train acc 0.7391, time 17.32\n",
            "epoch 16, test acc 0.7694,\n",
            "epoch 17, train loss 0.5074, train acc 0.7487, time 17.33\n",
            "epoch 17, test acc 0.7974,\n",
            "epoch 18, train loss 0.4902, train acc 0.7633, time 17.28\n",
            "epoch 18, test acc 0.7984,\n",
            "epoch 19, train loss 0.4764, train acc 0.7713, time 17.19\n",
            "epoch 19, test acc 0.7509,\n",
            "epoch 20, train loss 0.4519, train acc 0.7882, time 17.07\n",
            "epoch 20, test acc 0.8262,\n",
            "epoch 21, train loss 0.4374, train acc 0.7971, time 17.07\n",
            "epoch 21, test acc 0.8087,\n",
            "epoch 22, train loss 0.4218, train acc 0.8043, time 17.31\n",
            "epoch 22, test acc 0.8259,\n",
            "epoch 23, train loss 0.4112, train acc 0.8109, time 17.33\n",
            "epoch 23, test acc 0.8382,\n",
            "epoch 24, train loss 0.3868, train acc 0.8248, time 17.28\n",
            "epoch 24, test acc 0.8564,\n",
            "epoch 25, train loss 0.3747, train acc 0.8314, time 17.30\n",
            "epoch 25, test acc 0.8694,\n",
            "epoch 26, train loss 0.3602, train acc 0.8362, time 17.41\n",
            "epoch 26, test acc 0.8767,\n",
            "epoch 27, train loss 0.3434, train acc 0.8466, time 17.50\n",
            "epoch 27, test acc 0.8839,\n",
            "epoch 28, train loss 0.3337, train acc 0.8527, time 17.31\n",
            "epoch 28, test acc 0.8747,\n",
            "epoch 29, train loss 0.3140, train acc 0.8621, time 17.32\n",
            "epoch 29, test acc 0.9002,\n",
            "epoch 30, train loss 0.3045, train acc 0.8678, time 17.43\n",
            "epoch 30, test acc 0.9107,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uOjZCrG95uhY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define ResNet"
      ]
    },
    {
      "metadata": {
        "id": "jFHRB3HH5IR5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Block):\n",
        "    def __init__(self, n_channels, strides=1, nin=False, **kwargs):\n",
        "        super(ResBlock, self).__init__(**kwargs)\n",
        "        \n",
        "        self.conv1 = nn.Conv2D(n_channels, kernel_size=3, padding=1, strides=strides)\n",
        "        self.conv2 = nn.Conv2D(n_channels, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.nin   = None\n",
        "        if nin:\n",
        "            self.nin = nn.Conv2D(n_channels, kernel_size=1, strides=strides)\n",
        "            \n",
        "    def forward(self, X):\n",
        "        res = nd.relu(self.conv1(X))\n",
        "        res = self.conv2(res)\n",
        "        \n",
        "        if self.nin:\n",
        "            X = self.nin(X)\n",
        "            \n",
        "        return nd.relu(res + X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQj4IuPO7VWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Block):\n",
        "    \n",
        "    def __init__(self, n_outputs, **kwargs):\n",
        "        super(ResNet18, self).__init__(**kwargs)\n",
        "        \n",
        "        self.net = nn.Sequential()\n",
        "        self.net.add(\n",
        "            nn.Conv2D(64, kernel_size=3, strides=1, padding=1),\n",
        "            nn.BatchNorm(),\n",
        "            nn.Activation('relu')\n",
        "        )\n",
        "        \n",
        "        self.net.add(\n",
        "            self.add_block(64, 2, nin=True),\n",
        "            self.add_block(128, 2),\n",
        "            self.add_block(256, 2),\n",
        "            self.add_block(512, 2)\n",
        "        )\n",
        "        \n",
        "        self.net.add(nn.GlobalAvgPool2D(), nn.Dense(n_outputs))\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "        \n",
        "    def add_block(self, n_channels, n_blocks, nin=False):\n",
        "        net = nn.Sequential()\n",
        "\n",
        "        if not nin:\n",
        "            net.add(ResBlock(n_channels, 2, True))\n",
        "            n_blocks -= 1\n",
        "\n",
        "        for i in range(n_blocks):\n",
        "            net.add(ResBlock(n_channels))\n",
        "\n",
        "        return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHRr6bm4J5Ej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ctx = mx.gpu()\n",
        "\n",
        "loss = gloss.SoftmaxCrossEntropyLoss()\n",
        "resnet = ResNet18(2)\n",
        "resnet.initialize(init=init.Xavier(), force_reinit=True, ctx=ctx)\n",
        "\n",
        "def evaluate(net, test_iter, ctx):\n",
        "    acc, n = 0.0, 0\n",
        "    for X, y in test_iter:\n",
        "        X, y = X.as_in_context(ctx), y.astype('float32').as_in_context(ctx)\n",
        "        \n",
        "        y_hat = net(X)\n",
        "        acc += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
        "        n += y.size\n",
        "    return acc / n\n",
        "\n",
        "def train(net, train_iter, test_iter, num_epochs, batch_size, lr, ctx):\n",
        "    \n",
        "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
        "    \n",
        "    for i in range(1, num_epochs+1):\n",
        "        \n",
        "        train_acc, train_l, n, start = 0.0, 0.0, 0, time.time()\n",
        "        \n",
        "        for X, y in train_iter:\n",
        "            X, y = X.as_in_context(ctx), y.astype('float32').as_in_context(ctx)\n",
        "            \n",
        "            with autograd.record():\n",
        "                y_hat = net(X)\n",
        "                l = loss(y_hat, y).sum()\n",
        "            \n",
        "            l.backward()\n",
        "            trainer.step(batch_size)\n",
        "            train_l += l.asscalar()\n",
        "            train_acc += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
        "            n += y.size\n",
        "            \n",
        "        tm = time.time() - start\n",
        "        print('epoch %s, train loss %.4f, train acc %.4f, time %.2f' % \n",
        "             (i, train_l/n, train_acc/n, tm))\n",
        "        if test_iter:\n",
        "            test_acc = evaluate(net, test_iter, ctx)\n",
        "            print('epoch %s, test acc %.4f,' % (i, test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8TD7vIvZu1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "4f725bf6-453b-4e6d-af82-8ad9887f7b4c"
      },
      "cell_type": "code",
      "source": [
        "class VGGBlock(nn.Block):\n",
        "    def __init__(self, num_conv, num_channel, **kwargs):\n",
        "        super(VGGBlock, self).__init__(**kwargs)\n",
        "        \n",
        "        self.net = nn.Sequential()\n",
        "        for i in range(num_conv):\n",
        "            self.net.add(nn.Conv2D(num_channel, kernel_size=3, \n",
        "                              padding=1, activation='relu'))\n",
        "        self.net.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
        "            \n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "    \n",
        "class VGG(nn.Block):\n",
        "    def __init__(self, conv_arch, **kwargs):\n",
        "        super(VGG, self).__init__(**kwargs)\n",
        "        \n",
        "        self.net = nn.Sequential()\n",
        "        # Conv part\n",
        "        for num_conv, num_channel in conv_arch:\n",
        "            self.net.add(VGGBlock(num_conv, num_channel))\n",
        "        # Dense part\n",
        "        self.net.add(nn.Dense(512, activation='relu'), nn.Dropout(0.1),\n",
        "                     nn.Dense(512, activation='relu'), nn.Dropout(0.1),\n",
        "                     nn.Dense(2))\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "    \n",
        "vgg11_arch = ((2, 16), (2, 32), (2, 64))\n",
        "vgg11 = VGG(vgg11_arch)\n",
        "vgg11.initialize(init=init.Xavier(), force_reinit=True, ctx=ctx)\n",
        "vgg11"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (net): Sequential(\n",
              "    (0): VGGBlock(\n",
              "      (net): Sequential(\n",
              "        (0): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "    (1): VGGBlock(\n",
              "      (net): Sequential(\n",
              "        (0): Conv2D(None -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2D(None -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "    (2): VGGBlock(\n",
              "      (net): Sequential(\n",
              "        (0): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "    (3): Dense(None -> 512, Activation(relu))\n",
              "    (4): Dropout(p = 0.1, axes=())\n",
              "    (5): Dense(None -> 512, Activation(relu))\n",
              "    (6): Dropout(p = 0.1, axes=())\n",
              "    (7): Dense(None -> 2, linear)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "lgVBfPo5iLIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "782197e0-0a3a-4c57-ce4a-d1f3336f3330"
      },
      "cell_type": "code",
      "source": [
        "train(vgg11, train_iter, valid_iter, 10, batch_size, 1e-3, ctx)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 0.6960593647956849, train acc 0.500125, time 15.337489604949951\n",
            "epoch 1, test acc 0.5047523761880941,\n",
            "epoch 2, train loss 0.6942884759902954, train acc 0.4990625, time 15.745855569839478\n",
            "epoch 2, test acc 0.5130065032516258,\n",
            "epoch 3, train loss 0.6939391870498657, train acc 0.497125, time 15.529584169387817\n",
            "epoch 3, test acc 0.5300150075037519,\n",
            "epoch 4, train loss 0.6929404029846191, train acc 0.5091875, time 15.61025619506836\n",
            "epoch 4, test acc 0.5455227613806903,\n",
            "epoch 5, train loss 0.6923841013908386, train acc 0.51375, time 15.56535291671753\n",
            "epoch 5, test acc 0.5570285142571285,\n",
            "epoch 6, train loss 0.6917909717559815, train acc 0.526125, time 15.54853105545044\n",
            "epoch 6, test acc 0.5655327663831916,\n",
            "epoch 7, train loss 0.6917110614776611, train acc 0.5229375, time 15.60174012184143\n",
            "epoch 7, test acc 0.5732866433216608,\n",
            "epoch 8, train loss 0.6910117626190185, train acc 0.534875, time 15.599258661270142\n",
            "epoch 8, test acc 0.5842921460730365,\n",
            "epoch 9, train loss 0.6902290968894959, train acc 0.539875, time 15.669644117355347\n",
            "epoch 9, test acc 0.5872936468234117,\n",
            "epoch 10, train loss 0.6901924324035644, train acc 0.5464375, time 15.691535234451294\n",
            "epoch 10, test acc 0.5900450225112557,\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}